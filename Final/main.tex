\include{../preamble.tex}
\def\HWnum{Final Project}
\def\duedate{December 9, 2024}


\begin{document}

\section{Introduction}
\label{sec:introduction}

In a previous project this semester we have solved the time-independent Schr\"{o}dinger equation or energy eigenvalue equation by transforming it from a continuous second-order differential equation in space to a dicscrete eigenvalue problem.
For this problem, though, we were only interested in obtaining bound state solutions and entirely neglected the scattering states.
Since the time of Rutherford, results from scattering theory and experiments have provided us essential information about the structure and contents of our universe, and therefore, these scattering states are important in their own right.

For this work, we would like to explore scattering numerically in one dimension.
Even though from the outset this seems quite restrictive, developing the scattering formalism in one dimension will be quite instructive, and in addition, many three dimensional problems, namely those related to central potentials, can be reduced to one dimensional problems.

\section{Mathematical framework}
\label{sec:mathematical-framework}


The time-independent Schr\"{o}dinger equation is given by\footnote{Note that we work in natural units where $\hbar = c = 1$.}
\begin{align}
    -\frac{1}{2m} \dv[2]{\psi_{E}(x)}{x} + V(x) \psi_{E}(x) = E \psi_{E}(x)
,\end{align}
where $E$ is the energy eigenvalue of this equation and $\psi_{E}(x)$ is the corresponding eigenfunction.
When $E < \lim_{|x| \rightarrow \infty} V(x)$, we have bound states, usually discrete levels, which are normalizable since they fall off exponentially as $|x| \rightarrow \infty$.
On the other hand, when $E$ is larger than the potential in one of these asymptotic regions, we have a scattering state, and have a continuum of solutions.
In the asymptotic regions, however, our solutions are of the generic form $e^{\pm i k x}$ and are therefore not normalizable and hence not physical.
To solve definite problems, we must work with physical solutions in the context of wavepackets of the form
\begin{align}
    \psi(x) = \int \frac{\dd{k}}{\sqrt{2 \pi}} \widetilde{\psi}(k) e^{i k x}
,\end{align}
where the time-dependence can be generated by the time-evolution operator.
Taking motivation from this, we simulate scattering, which inherently requires dynamics, in two ways. 

\subsection{Finite differences}
\label{ssec:finite-differences}

For our first numerical method, we solve the time-dependent Schr\"{o}dinger equation 
\begin{align}
    i \pdv{\Psi(x,t)}{t} = -\frac{1}{2m} \pdv[2]{\Psi(x,t)}{x} + V(x) \Psi(x,t)
.\end{align}
directly by implementing a finite difference scheme.
Using a forward difference formula for the time derivative, the three-point formula for the second derivative, and rearranging, we obtain
\begin{align}
    \Psi_{n}^{(m + 1)} = \Psi_{n}^{(m)} + i \Delta t \Bigg( \frac{\Psi_{n-1}^{(m)} - 2 \Psi_{n}^{(m)} + \Psi_{n+1}^{(m)}}{2m \Delta x^2} - V_{n} \Psi_{n}^{(m)} \Bigg)
,\end{align}
where $\Psi_{n}^{(m)} = \Psi(x_n,t_{m})$, $x_{n} = x_0 + n \Delta x$, and $t_{m} = m \Delta t$.
Thus, we have a sequence defined by $\Psi_{n}^{(m)} = U^{m} \Psi_{n}^{(0)}$, where
\begin{align}
    U_{kn} = \delta_{kn} - i \Delta t H_{kn}
,\end{align}
where the discretized Hamiltonian
\begin{align}
    H_{kn} = -\frac{\delta_{k-1,n} - 2 \delta_{kn} + \delta_{k+1,n}}{2m \Delta x^2} + V_{k} \delta_{kn}
.\end{align}
Such an equation reminds us of the unitary time evolution, which can be explored by direct matrix multiplication:
\begin{align}
    U_{kn}^{\dagger} U_{nk'} &= ( \delta_{kn} + i \Delta t H_{kn}^{\dagger} ) ( \delta_{nk'} - i \Delta t H_{nk'} ) = \delta_{k k'} + i \Delta t ( H_{kk'}^{\dagger} - H_{kk'} ) + \Delta t^2 H_{kn}^{\dagger} H_{nk'} \nonumber \\
    &= \delta_{kk'} + \mathcal{O}(\Delta t^2)
.\end{align}
Herein lies a primary difficulty of implementing this method: the eigenvalues of $U$ essentially scale the eigenvector components of our initial wavevector.
Hence, for stability, we would like to select $\Delta t$ and $\Delta x$ such that all of these eigenvalues are less than one.
Unfortunately, this is not possible since the eigenvalues of a unitary matrix have unit norm, prohibiting us from performing our time evolution in this manner.


\subsection{Fourier transform}

If we cannot perform time evolution directly, perhaps we can take inspiration from a different place.
We know from quantum mechanics that our unitary time evolution operator $U(t,t')$ acts as $\Psi(x,t) = U(t,t') \Psi(x,t')$ and therefore satisfies the differential equation
\begin{align}
    i \pdv{U(t,t')}{t} = H U(t,t')
,\end{align}
which has solution
\begin{align}
    U(t,t') = e^{-i H (t - t')}
\end{align}
if $H$ is independent of time, which will be the case in our scattering problems.
Let us write $H = H_0 + V$, where $H_0$ is the free-particle Hamiltonian and $V$ contains the potential terms.
If we select our time step $\Delta t$ between time slices $t_{m}$ and $t_{m+1}$, then using the Baker-Campbell-Hausdorff formula, we can write
\begin{align}
    U(\Delta t) = e^{-i H \Delta t} \approx e^{-i H_0 \Delta t} e^{-i V \Delta t} \Big( 1 + \mathcal{O}(\Delta t^2) \Big)
.\end{align}
Since we are working in the context of wave-packets, we can act directly on the state at time $t_{m}$ as follows
\begin{align}
    \Psi(x,t_{m+1}) &= U(\Delta t) \Psi(x,t_{m}) = e^{-i V(x) \Delta t} \int \frac{\dd{k}}{\sqrt{2 \pi}} \widetilde{\Psi}(k,t_{m}) e^{-i H_0 \Delta t} e^{i k x} \nonumber \\
    &= e^{-i V(x) \Delta t} \int \frac{\dd{k}}{\sqrt{2 \pi}} \widetilde{\Psi}(k,t_{m}) e^{- i k^2 \Delta t / (2m)} e^{i k x}
.\end{align}
Thus, for small time steps, our potential changes the phase of the wave-function locally and the free part of the Hamiltonian propagates our modes according to their velocity $k/m$.

Because the above equation is set up on the continuous spatial domain we could set up our wave-packets as functions numerically and implement a numerical quadrature to take the Fourier transform at each $x$, but this could become quite computationally expensive, resource and time-wise.
Another approach utilizes the fast-fourier transform, which requires us to discretize our spatial domain.
Doing so, however, also requires conjugate momentum domain to be discretized.
The details for computing the Fourier transform above can be found in App. \ref{app:relating-the-continuous-and-discrete-fourier-transforms}.


\section{Freely propagating Gaussian wave packet}
\label{sec:freely-propagating-gaussian-wave-packet}

To test that our numerical solver works, we choose an initial wave function
\begin{align}
    \Psi(x,0) = \frac{1}{(2 \pi \sigma^2)^{1/4}} \exp{-\frac{(x - x_{0})^2}{4 \sigma^2}} \exp{i k x}
,\end{align}
which is a Gaussian density at $t = 0$ with average momentum $k$.
We can now use propagator formalism to determine the wave function at any later time $t$ as follows:
\begin{align}
    \Psi(x,t) &= \int \dd{x'} K(x,x';t) \Psi(x',0) \nonumber \\
              &= \sqrt{\frac{m}{2 \pi i t}} \frac{1}{(2 \pi \sigma^2)^{1/4}} \int_{-\infty}^{\infty} \dd{x'} \exp{-\frac{m(x - x')^2}{2 i t} - \frac{(x' - x_0)^2}{4 \sigma^2} + i k x'}
.\end{align}
The intermediate form of the wave function is not too interesting for our purposes, but the probability density
\begin{align}
    |\Psi(x,t)|^2 = \frac{1}{\sqrt{2 \pi \sigma^2}} \frac{2 \sigma^2 m}{\sqrt{ 4 \sigma^4 m^2 + t^2 }} \exp{ -\frac{2 m^2 \sigma^2 [ x - (x_0 + k t / m) ]^2}{4 \sigma^{4} m^2 + t^2} }
.\end{align}

\appendix

\section{Stability of the explicit and implicit finite difference methods}
\label{app:stability-of-the-explicity-and-implicit-finite-difference-methods}

In this work, the operators we deal with are typically either hermitian or unitary, both of which are special cases of the broader class of normal matrices $A$ which commute with their hermitian conjugate $A^{\dagger}$.
There is a theorem of equivalence statements in linear algebra that defines a normal matrix and states that any normal matrix $A$ is diagonalizable via a unitary similarity transformation and that there exists a set of eigenvectors which forms an complete orthonormal basis for the $n$-dimensional vector space.
Let us denote the spectrum of $A$ by the set $\{ a_{n} \}$ and the corresponding set of eigenvectors by $\{ x^{(n)} \}$
Thus, any vector $\Psi$, which is analogous to our discretized wave-function, we can write
\begin{align}
    \Psi = \sum_{n} c_{n} x^{(n)}
,\end{align}
where $c_{n} = \Psi^{\dagger} x^{(n)}$.
It follows then, that repeated action of $A$ on $\Psi$ yields
\begin{align}
    \Psi^{(k)} = A^{k} \Psi = \sum_{n} c_{n} a_{n}^{k} x^{(n)}
.\end{align}
If we now consider $A$ to be nearly unitary, as in the finite difference methods above for time-evolution, then we see our fundamental issue with implementing the finite difference methods above.
Indeed, because of the discretization effects, our eigenvalues $a_{n}$ have approximately unit norm but not quite.
Thus, for large times (i.e. in the limit $k \rightarrow \infty$), we have
\begin{align}
    A^{k} \Psi \rightarrow c_{n_{\rm max}} a_{n_{\rm max}}^{k} x^{(n_{\rm max})}
,\end{align}
where $n_{\rm max} = {\rm argmax}(\{ a_{n} \})$.
Hence, if $a_{n_{\rm max}} > 1$, then our solution explodes, and if $a_{\rm max} < 1$, then our solution vanishes at large times.
Of course then, even the slightest bit of unitarity violation in our matrix evolution is a fatal flaw for a finite difference method propagating the entire wave-function, both its real and imaginary parts, at equal times.

\section{Relating the continuous and discrete Fourier transforms}
\label{app:relating-the-continuous-and-discrete-fourier-transforms}

The expressions we use for the continuous fourier and inverse fourier transforms of some function $f(x)$ are as follows:
\begin{align}
    f(x) &= \int \frac{\dd{k}}{\sqrt{2 \pi}} \tilde{f}(k) e^{i k x} \\
    \tilde{f}(k) &= \int \frac{\dd{x}}{\sqrt{2 \pi}} f(x) e^{-ikx}
.\end{align}
On the other hand, for a collection of discrete data points $f_{n}$, their discrete Fourier and inverse Fourier transforms are as follows (consistent with the \textit{numpy} conventions):
\begin{align}
    f_{n} &= \frac{1}{\sqrt{N}} \sum_{m=0}^{N-1} F_{m} e^{2 \pi i \frac{m n}{N}} \\
    F_{m} &= \frac{1}{\sqrt{N}} \sum_{n=0}^{N-1} f_{n} e^{-2 \pi i \frac{m n}{N}}
.\end{align}

We can write the grid points in $x$-space as $x_{n} = x_0 + n \Delta x$ and those in $k$-space as $k_{m} = m \Delta k$ with $n,m \in \{ 0,1,\ldots,N-1 \}$, where
\begin{align}
    \Delta x \Delta k = \frac{2 \pi}{N}
.\end{align}


    
\end{document}
